{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ML Foundations - Capstone Project\n",
        "Theekshana Wijesinghe\n",
        "\n",
        "### Project: Rank nursery applications\n",
        "\n",
        "Data source: https://archive.ics.uci.edu/dataset/76/nursery\n",
        "\n",
        "#### Description\n",
        "\n",
        "This project is based off of one of the popular datasets in UCI Machine Learning Repository's, known as **Nursery**.\n",
        "\n",
        "\n",
        "*Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools.*\n",
        "\n",
        "The goal of this project is to generate a Machine Learning model for the hierarchical decision model and to predict the rank of the nursery applications.\n",
        "\n",
        "There are 8 features in the dataset all are **categorical** and the target is a **multiclass** variable. Since all the features are categorical, identifying relation between features and target is a challange.\n",
        "\n",
        "This problem is **Classification** problem with a multiclass categorization and I will be using Supervised learning approach to solve the problem.\n"
      ],
      "metadata": {
        "id": "utszdqEP9oFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW-IrG1yoGtq"
      },
      "outputs": [],
      "source": [
        "#Load libraries\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.metrics import RocCurveDisplay, accuracy_score, precision_score, f1_score, recall_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from joblib import dump\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "column_names = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://github.com/theekshanawj/capstone-project-slasscom/blob/main/dataset/nursery.data?raw=true', names=column_names)"
      ],
      "metadata": {
        "id": "7GyO4oKoZxaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See data\n",
        "\n",
        "print(f\"Shape {data.shape}\")\n",
        "\n",
        "data.describe(include='all').transpose()\n",
        "\n",
        "print(data.dtypes)\n"
      ],
      "metadata": {
        "id": "cbyHXw4FaD-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data repo mentions no missing value, but let's verify\n",
        "\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "nPbwqPdFaije"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find duplicates\n",
        "duplicates = data.loc[data.duplicated()]\n",
        "duplicates"
      ],
      "metadata": {
        "id": "u0PKYoJGYf90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's draw bar charts to see data\n",
        "\n",
        "def drawBarGraph(df, field, ax, title):\n",
        "  df[field].value_counts().plot(kind='bar', ax=ax, title=title)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5)\n",
        "\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(15)\n",
        "\n",
        "idx = 0\n",
        "\n",
        "for i in range(2):\n",
        "  for j in range(5):\n",
        "    if(idx < len(column_names)):\n",
        "      field = column_names[idx]\n",
        "      drawBarGraph(data, field, axes[i,j], field)\n",
        "      idx += 1\n"
      ],
      "metadata": {
        "id": "pgCU2jtUB-RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation between categorical data\n",
        "\n",
        "[Chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test) will be approach used here to find the correlation between two categorical variables.\n",
        "\n",
        "**scipy.stats** library will be used here\n",
        "\n",
        "If p value is <= 0.05 we can safetly assume that there is a relation between two variables\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BlUgIVQiDRjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chi-squared test for feature selection\n",
        "\n",
        "p_val = []\n",
        "\n",
        "all_feature_columns = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health']\n",
        "\n",
        "\n",
        "def calculate_p_values():\n",
        "  for i in all_feature_columns:\n",
        "    crosstab = pd.crosstab(data['class'], data[i])\n",
        "    c, p, dof, expected = chi2_contingency(crosstab)\n",
        "    p_val.append(np.abs(p))\n",
        "\n",
        "    plt.figure(figsize=(6,2))\n",
        "    sns.heatmap(crosstab, annot=True, cmap=\"YlGnBu\")\n",
        "\n",
        "\n",
        "calculate_p_values()\n",
        "\n",
        "p_values = pd.DataFrame({ 'p_value': p_val, 'field': all_feature_columns }, index=all_feature_columns)\n",
        "\n",
        "p_values.plot(kind='bar', title='Probability value of Chi-Square test')\n",
        "\n",
        "filtered_field = p_values.loc[p_values['p_value'] <= 0.05 ]\n",
        "\n",
        "filtered_field\n"
      ],
      "metadata": {
        "id": "RNLyT0YBZu7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the uniques of target variable and assign numerical value\n",
        "# This is categorical and ordinal in a way\n",
        "\n",
        "data['class'].unique()\n",
        "\n",
        "print(data['class'].value_counts())\n",
        "\n",
        "\n",
        "class_map =  {\n",
        "    'not_recom': 0,\n",
        "    'recommend': 1,\n",
        "    'very_recom': 2,\n",
        "    'priority': 3,\n",
        "    'spec_prior': 4\n",
        "}\n",
        "\n",
        "\n",
        "y = data['class'].replace(class_map)\n",
        "\n",
        "y.sample(10)\n"
      ],
      "metadata": {
        "id": "QFV2RtUsyv3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record with recommend value as the target is very small, this could be problametic\n",
        "# First I will keep this in the dataset and see the results and then delete it to see how this will impact the model accuracy\n",
        "\n",
        "\n",
        "data.loc[data['class'] == 'recommend']\n",
        "\n",
        "\n",
        "# Learnt lesson:  We get 'UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.' when running SVC\n",
        "# Therefore it is required to remove recommend class"
      ],
      "metadata": {
        "id": "Wv9K80BF6Yzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's model using logistic regression\n",
        "# One hot encoding is done using sklearn pipeline, this avoid tedious operations using Pandas\n",
        "# This way we can easily use the same when we try to predict future values\n",
        "\n",
        "\n",
        "# Define the type of model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "# Let's start with the features that showed p = 0 for chi-squared test\n",
        "feature_columns = ['has_nurs', 'health']\n",
        "\n",
        "# Define the transfomers\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", categorical_transformer, feature_columns), #All the feature columns are categorical\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "X = data[feature_columns]\n",
        "\n",
        "# Transfomr y into categorical column, this is same as above\n",
        "\n",
        "y = data['class'].replace(class_map)\n",
        "\n",
        "pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)]\n",
        ")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "predict = pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "ze2R19DknNyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate results\n",
        "\n",
        "print(predict.shape)\n",
        "\n",
        "result = pd.DataFrame({ 'y_actual': y_test, 'y_pred': predict })\n",
        "\n",
        "result.plot(kind='scatter', x='y_actual', y='y_pred')\n",
        "\n",
        "print(result)\n",
        "\n",
        "pd.crosstab(result['y_actual'], result['y_pred'])"
      ],
      "metadata": {
        "id": "YBl-vnIPIkPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate the model metrices\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(result['y_actual'], result['y_pred'])}\")\n",
        "\n",
        "print(f\"Prcision: {precision_score(result['y_actual'], result['y_pred'], average='weighted')}\")\n",
        "\n",
        "print(f\"Recall: {recall_score(result['y_actual'], result['y_pred'], average='weighted')}\")\n",
        "\n",
        "print(f\"F1 score: {f1_score(result['y_actual'], result['y_pred'], average='weighted')}\")\n"
      ],
      "metadata": {
        "id": "o4hkKeTOItrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiclass Receiver Operating Characteristic (ROC)\n",
        "\n",
        "Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
      ],
      "metadata": {
        "id": "cFsUZe7E6Pig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve\n",
        "\n",
        "def draw_roc_curves(pipe, X_test, y_train, y_test, model_name):\n",
        "\n",
        "  y_score = pipe.predict_proba(X_test)\n",
        "\n",
        "  label_binarizer = LabelBinarizer().fit(y_train)\n",
        "\n",
        "  y_onehot_test = label_binarizer.transform(y_test)\n",
        "\n",
        "  for key in class_map.keys():\n",
        "    interested_label_id = class_map[key]\n",
        "\n",
        "    class_ids = np.flatnonzero([class_map[key] == label_binarizer.classes_])\n",
        "\n",
        "    if len(class_ids) > 0:\n",
        "      interested_label_id = class_ids[0]\n",
        "      RocCurveDisplay.from_predictions(\n",
        "          y_onehot_test[:, interested_label_id],\n",
        "          y_score[:, interested_label_id],\n",
        "          name=f\"{key} against others\",\n",
        "          color=\"darkorange\",\n",
        "      )\n",
        "      plt.axis(\"square\")\n",
        "      plt.xlabel(\"False Positive Rate\")\n",
        "      plt.ylabel(\"True Positive Rate\")\n",
        "      plt.title(f\"{key} vs Rest for {model_name}\")\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "draw_roc_curves(pipe, X_test, y_train, y_test, \"LG\")\n"
      ],
      "metadata": {
        "id": "ea7nEiqHgXn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Above model is based of two features let's change the features and see if it impacts the metrices\n",
        "\n",
        "# Define the type of model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "features_1 = ['has_nurs', 'health']\n",
        "features_2 = ['parents', 'has_nurs', 'children', 'housing', 'social', 'health'] # Without form and finance that showed high p value in above\n",
        "features_3 = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health']\n",
        "\n",
        "features_list = [features_1, features_2, features_3]\n",
        "\n",
        "\n",
        "def get_pipeline(model, features):\n",
        "\n",
        "    categorical_transformer = Pipeline(\n",
        "        steps=[\n",
        "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"cat\", categorical_transformer, features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return Pipeline(\n",
        "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def get_features(features):\n",
        "  return data[features]\n",
        "\n",
        "\n",
        "def get_target():\n",
        "  return data['class'].replace(class_map)\n",
        "\n",
        "\n",
        "def train_model(pipe, X_train, y_train):\n",
        "      pipe.fit(X_train, y_train)\n",
        "\n",
        "def calculate_accuracy(result):\n",
        "  return round(accuracy_score(result['y_actual'], result['y_pred']), 3)\n",
        "\n",
        "def calculate_precision(result):\n",
        "  return round(precision_score(result['y_actual'], result['y_pred'], average='weighted'), 3)\n",
        "\n",
        "def calculate_f1_score(result):\n",
        "  return round(f1_score(result['y_actual'], result['y_pred'], average='weighted'), 3)\n",
        "\n",
        "def calculate_recall(result):\n",
        "  return round(recall_score(result['y_actual'], result['y_pred'], average='weighted'), 3)\n",
        "\n",
        "\n",
        "def evaluate_results(features, y_test, predict):\n",
        "\n",
        "    feature_name = f\"{features}\"\n",
        "\n",
        "    print(f\"Features: {feature_name}\")\n",
        "\n",
        "    result = pd.DataFrame({ 'y_actual': y_test, 'y_pred': predict })\n",
        "\n",
        "    result.plot(kind='scatter', x='y_actual', y='y_pred', title=feature_name)\n",
        "\n",
        "    pd.crosstab(result['y_actual'], result['y_pred'])\n",
        "\n",
        "    print(f\"Accuracy: {calculate_accuracy(result)}\")\n",
        "\n",
        "    print(f\"Prcision: {calculate_precision(result)}\")\n",
        "\n",
        "    print(f\"Recall: {calculate_recall(result)}\")\n",
        "\n",
        "    print(f\"F1 score: {calculate_f1_score(result)}\")\n",
        "\n",
        "\n",
        "# Extract everything to a function\n",
        "def evaluate_model_with_variable_features(model, features):\n",
        "\n",
        "    pipe = get_pipeline(model, features)\n",
        "\n",
        "    X = get_features(features)\n",
        "    y = get_target()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=30)\n",
        "\n",
        "    train_model(pipe, X_train, y_train)\n",
        "\n",
        "    predict = pipe.predict(X_test)\n",
        "\n",
        "    evaluate_results(features, y_test, predict)\n",
        "\n",
        "\n",
        "for feature in features_list:\n",
        "  evaluate_model_with_variable_features(model, feature)\n",
        "\n",
        "\n",
        "# We can conclude that highest accuracy, precision and f1 score is with all the features included"
      ],
      "metadata": {
        "id": "7dHrcXadJteG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 'recommend' is not available in the results and we saw only two records were available in the dataset\n",
        "# Let's remove those two and see what happens\n",
        "\n",
        "print(data.loc[data['class'] == 'recommend'])\n",
        "\n",
        "data.drop(index=[0,3], inplace=True)\n",
        "\n",
        "print(data.loc[data['class'] == 'recommend'])\n",
        "\n",
        "# New class map\n",
        "class_map =  {\n",
        "    'not_recom': 0,\n",
        "    'very_recom': 1,\n",
        "    'priority': 2,\n",
        "    'spec_prior': 3\n",
        "}\n"
      ],
      "metadata": {
        "id": "wvn03ws2PWw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's again evaluate the model\n",
        "\n",
        "evaluate_model_with_variable_features(model, ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health']) # All the features are included\n"
      ],
      "metadata": {
        "id": "jq-io8fXRLAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now use other models along with the regression model\n",
        "\n",
        "#Models, here models are used with default params except for LogisticRegression to identify the best model to optimise further with params\n",
        "models = [LogisticRegression(max_iter=500),\n",
        "            RandomForestClassifier(),\n",
        "              KNeighborsClassifier(),\n",
        "                svm.SVC(probability=True)] # probability=True; This is to draw the ROC curve\n",
        "\n",
        "feature_columns = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health']\n",
        "\n",
        "\n",
        "def get_model_eval_score(result_df):\n",
        "  return {\n",
        "      'accuracy': calculate_accuracy(result_df),\n",
        "      'precision': calculate_accuracy(result_df),\n",
        "      'recall': calculate_recall(result_df),\n",
        "      'f1_score': calculate_f1_score(result_df)\n",
        "  }\n",
        "\n",
        "def get_model_name(model):\n",
        "  return str(model).split('(')[0]\n",
        "\n",
        "def evaluate_model(model):\n",
        "\n",
        "  pipe = get_pipeline(model, feature_columns)\n",
        "\n",
        "  X = get_features(feature_columns)\n",
        "  y = get_target()\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=30)\n",
        "\n",
        "  train_model(pipe, X_train, y_train)\n",
        "\n",
        "  predict = pipe.predict(X_test)\n",
        "\n",
        "  result = pd.DataFrame({'y_actual': y_test, 'y_pred': predict })\n",
        "\n",
        "  # can be used to draw roc curves, uncomment to see results\n",
        "  # draw_roc_curves(pipe, X_test, y_train, y_test, get_model_name(model))\n",
        "\n",
        "  return get_model_eval_score(result)\n",
        "\n",
        "\n",
        "\n",
        "model_evals = list(map(evaluate_model, models))\n",
        "\n",
        "mode_names = list(map(get_model_name, models))\n",
        "\n",
        "\n",
        "def get_eval_df():\n",
        "  df_object = {}\n",
        "  for idx, model in enumerate(mode_names):\n",
        "    df_object[model] = model_evals[idx]\n",
        "\n",
        "  return df_object\n",
        "\n",
        "eval_object = get_eval_df()\n",
        "\n",
        "pd.DataFrame(get_eval_df(), index=['accuracy', 'precision', 'recall', 'f1_score']).plot(kind='bar')\n",
        "\n",
        "eval_object\n"
      ],
      "metadata": {
        "id": "rjY_OF6sbQ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From above metric table, we can clearly see Support Vector Classification has the best metrices and RandomForestClassifier coming close\n",
        "\n",
        "# Now let'see if we can improve the model using GridSearchCV\n",
        "\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "\n",
        "svc = svm.SVC(probability=True)\n",
        "\n",
        "model = GridSearchCV(svc, parameters, scoring='f1_weighted', cv=5)\n",
        "\n",
        "evaluate_model(model)\n",
        "\n",
        "print(model.best_score_)\n",
        "print(model.best_params_)\n",
        "print(model.best_estimator_)\n"
      ],
      "metadata": {
        "id": "WZYPzMWL97hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally let's save the model\n",
        "\n",
        "\n",
        "pipe = get_pipeline(model, feature_columns)\n",
        "\n",
        "X = get_features(feature_columns)\n",
        "y = get_target()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=30)\n",
        "\n",
        "train_model(pipe, X_train, y_train)\n",
        "\n",
        "dump(pipe, 'svc_pipeline.joblib')\n"
      ],
      "metadata": {
        "id": "_e3qFdz0K4RU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}